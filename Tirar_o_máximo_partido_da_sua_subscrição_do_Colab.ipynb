{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgeluizetibr/7guis/blob/master/Tirar_o_m%C3%A1ximo_partido_da_sua_subscri%C3%A7%C3%A3o_do_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Tirar o máximo partido da sua subscrição do Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## GPUs mais rápidas\n",
        "\n",
        "<p>Os utilizadores que compraram um dos planos pagos do Colab têm acesso a GPUs premium. Pode atualizar as definições da GPU do bloco de notas em <code>Tempo de execução &gt; Alterar tipo de tempo de execução</code> no menu para ativar o acelerador premium. Selecionar uma GPU premium, sujeita a disponibilidade, pode dar-lhe acesso a uma GPU Nvidia V100 ou A100.</p>\n",
        "<p>A versão sem custo financeiro do Colab dá acesso às GPUs T4 da Nvidia, sujeito a restrições de quota e disponibilidade.</p>\n",
        "\n",
        "Pode ver que GPU lhe foi atribuída em qualquer altura ao executar a seguinte célula. Se o resultado da execução da célula de código abaixo for \"Not connected to a GPU\", pode alterar o tempo de execução ao aceder a <code>Tempo de execução &gt; Alterar tipo de tempo de execução</code> no menu para ativar um acelerador de GPU e, em seguida, voltar a executar a célula de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "ef78f0c0-5817-4e36-faf6-4cb95199a7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 14 14:34:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0              26W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "Para usar uma GPU com o seu bloco de notas, selecione o menu <code>Tempo de execução &gt; Alterar tipo de tempo de execução</code> e, em seguida, defina o menu pendente de acelerador de hardware para GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## Mais memória\n",
        "\n",
        "Os utilizadores que compraram um dos planos pagos do Colab têm acesso a VMs &#40;máquinas virtuais&#41; com muita memória, quando estão disponíveis.\n",
        "Pode ver quanta memória tem disponível em qualquer altura ao executar a seguinte célula de código. Se o resultado da execução da célula de código abaixo for \"Not using a high-RAM runtime\", pode ativar um tempo de execução com RAM alta em <code>Tempo de execução &gt; Alterar tipo de tempo de execução</code> no menu. Em seguida, selecione RAM alta no menu pendente Forma do tempo de execução. Depois, execute novamente a célula de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1G82GuO-tez",
        "outputId": "dff1b4a9-587d-4369-b403-93800d7d9a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Tempos de execução mais longos\n",
        "\n",
        "Todos os tempos de execução do Colab são reiniciados após um certo período &#40;que é mais rápido se o tempo de execução não estiver a executar código&#41;. Os utilizadores do Colab Pro e Pro+ têm acesso a tempos de execução mais longos do que os que usam o Colab sem custo financeiro.\n",
        "\n",
        "## Execução em segundo plano\n",
        "\n",
        "Os utilizadores do Colab Pro+ têm acesso à execução em segundo plano, na qual os blocos de notas continuam a ser executados mesmo depois de ter fechado um separador do navegador. Esta opção está sempre ativada nos tempos de execução do Pro+ desde que tenha unidades de computação disponíveis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Reduzir os limites de recursos no Colab Pro\n",
        "\n",
        "Os seus recursos não são ilimitados no Colab. Para tirar o máximo partido do Colab, evite usar recursos quando não precisar deles. Por exemplo, use apenas uma GPU quando for necessário e feche os separadores do Colab quando terminar.\n",
        "\n",
        "Se encontrar limitações, pode reduzi-las ao comprar mais unidades de computação através do modelo de pagamento mediante utilização. Qualquer pessoa pode comprar unidades de computação através do <a href=\"https://colab.research.google.com/signup\">pagamento mediante utilização</a>. Não é necessária uma subscrição."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Envie-nos o seu feedback!\n",
        "\n",
        "<p>Se quiser dar-nos algum feedback, informe-nos. A melhor forma de enviar feedback é através do menu Ajuda &gt; \"Enviar feedback…\". Se encontrar limites de utilização no Colab Pro, considere subscrever o Pro+.</p>\n",
        "<p>Se detetar erros ou outros problemas de faturação &#40;pagamentos&#41; no Colab Pro, Pro+ ou pagamento mediante utilização, envie um email para <a href=\"mailto:colab-billing@google.com\">colab-billing@google.com</a>.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## Mais recursos\n",
        "\n",
        "### Trabalhar com blocos de notas no Colab\n",
        "- [Vista geral do Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guia sobre Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importar bibliotecas e instalar dependências](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Guardar e carregar blocos de notas no GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [Formulários interativos](/notebooks/forms.ipynb)\n",
        "- [Widgets interativos](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Trabalhar com dados\n",
        "- [Carregar dados: Drive, Sheets e Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [Gráficos: visualizar dados](/notebooks/charts.ipynb)\n",
        "- [Comece a utilizar o BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "Estes são alguns dos blocos de notas do curso online de aprendizagem automática da Google. Consulte o <a href=\"https://developers.google.com/machine-learning/crash-course/\">Website do curso completo</a> para obter mais informações.\n",
        "- [Introdução ao Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Regressão linear com tf.keras ao utilizar dados sintéticos](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Usar hardware acelerado\n",
        "- [TensorFlow com GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow com TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Exemplos de aprendizagem automática\n",
        "\n",
        "Para ver exemplos completos das análises interativas de aprendizagem automática possibilitadas pelo Colaboratory, consulte estes tutoriais através dos modelos do <a href=\"https://tfhub.dev\">TensorFlow Hub</a>.\n",
        "\n",
        "Alguns exemplos em destaque:\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">Preparar novamente um classificador de imagens</a>: crie um modelo do Keras baseado num classificador de imagens pré-preparado para distinguir flores.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">Classificação de texto</a>: classifique as críticas cinematográficas do IMDB como <em>positivas</em> ou <em>negativas</em>.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">Transferência de estilo</a>: utilize a aprendizagem avançada para transferir o estilo entre imagens.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">Perguntas e respostas sobre o codificador de frases universais multilíngue</a>: utilize um modelo de aprendizagem automática para responder a perguntas do conjunto de dados SQuAD.\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">Tipo de interpolação de vídeo</a>: preveja o que aconteceu num vídeo entre o primeiro e o último frame.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tirar o máximo partido da sua subscrição do Colab",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}